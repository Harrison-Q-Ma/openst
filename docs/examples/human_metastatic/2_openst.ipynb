{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Integrating imaging and sequencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous step, the flow-cell barcodes were mapped to spatial coordinates, and the transcriptomic reads were processed and mapped in tissue space with `spacemake`. \n",
    "\n",
    "With those steps, you obtained `h5ad` objects where each cell is a [hexbin](https://h3geo.org/docs/comparisons/hexbin/), containing around ~400 of the 0.6Âµm barcoded spots, and can be used already for analysis.\n",
    "\n",
    "For more accurate single-cell representations from the spatial data, we perform image-informed segmentation. This involves three major steps:\n",
    "\n",
    "1. Pairwise alignment between the imaging and spatial transcriptomics modality\n",
    "2. Segmentation of the imaging modality\n",
    "3. Assign transcripts into individual (segmented) cells.\n",
    "\n",
    "We will illustrate how to do this in a semiautomatic manner: that is, running the coarse alignment in an automatic fashion, and the fine alignment (to fiducial marks) via a Graphical User Interface (GUI), in an interactive manner. This is typically a quick process (~5 minutes per sample of 12 tiles)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start again at the `spacemake` root folder:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "```bash\n",
    "WORKDIR=\"~/openst_demo\"\n",
    "cd $WORKDIR/spacemake\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stitching of spatial coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ran `spacemake` with a run mode that meshes the data, and no run mode that does not mesh the data, you will need to spatially stitch the single spots data into a single file before pairwise alignment and segmentation. That is, the typical output for `spacemake` consists of several `h5ad` files, one per `tile`, and we require a single file for the sample that contains all tiles in their correct spatial offsets. We do this automatically by running the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "```bash\n",
    "for sample in mLN_S{2..4}; do\n",
    "    openst from_spacemake \\\n",
    "        --project-id mLN \\\n",
    "        --sample-id \"$sample\" \\\n",
    "        spatial_stitch \\\n",
    "        --tile-coordinates $WORKDIR/spacemake/puck_data/openst_coordinate_system.csv\n",
    "done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There will be a new `h5ad` file that contains all spatial coordinates at the single spot level (0.6 micron resolution), instead of the arbitrary meshing to pseudocells. This is what we require for taking advantage of image-based cell segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging the modalities (image and ST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that the image was stitched automatically with the `openst` code above. Then, all files will be at the expected locations and you can run the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "```bash\n",
    "for sample in mLN_S{2..4}; do\n",
    "    openst from_spacemake \\\n",
    "        --project-id mLN \\\n",
    "        --sample-id \"$sample\" \\\n",
    "        merge_modalities \\\n",
    "        --image-in \"${WORKDIR}\"/raw_data/images/\"${sample}\".tif\n",
    "done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will store the image data into the `h5ad` object, for pairwise alignment and cell segmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pairwise alignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!! info\n",
    "    Pairwise alignment should be done in a per-section basis, since manual, qualitative validation of the results is recommended. \n",
    "\n",
    "    Therefore, make sure to repeat these steps for the sections `mLN_S2`, `mLN_S3` and `mLN_S4`.\n",
    "\n",
    "You can run automatic pairwise alignment of the two modalities by running this command:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "```bash\n",
    "openst from_spacemake \\\n",
    "    --project-id mLN \\\n",
    "    --sample-id mLN_S2 \\\n",
    "    pairwise_aligner \\\n",
    "    --device cuda\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pairwise alignment happens in two steps, coarse and fine. At the coarse level, low-resolution image and ST data are used, then once the rotation, flip level and offset is more or less set, high-resolution image and ST are used for finding the most accurate alignment, relying on small features from the tissue and the concentric circles (fiducial marks) that are visible at both image and the ST modalities.\n",
    "\n",
    "It is good practice to check the quality of the alignment before proceeding with the rest of the pipeline. We provide a GUI tool to do this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "```bash\n",
    "openst from_spacemake \\\n",
    "    --project-id mLN \\\n",
    "    --sample-id mLN_S2 \\\n",
    "    manual_pairwise_aligner\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find more instructions for how to use this tool in this [YouTube video](https://www.youtube.com/watch?v=Fjh4huosVPY). \n",
    "\n",
    "If the alignment does not look optimal (e.g., fiducial circles visible at each tile, across both modalities, do not look perfectly aligned), you can use this tool for manual refinement of the alignment. \n",
    "\n",
    "This tool helps to store user-selected keypoints as a standard `json` file, that can be used to compute the transformation matrices that align the ST data into the imaging modality. When such a `json` file is available, you can compute the optimal transformation with the following tool:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "```bash\n",
    "openst from_spacemake \\\n",
    "      --project-id mLN \\\n",
    "      --sample-id mLN_S2 \\\n",
    "      apply_transform \\\n",
    "      --keypoints-in keypoints.json \\\n",
    "      --spatial-key-in obsm/spatial_pairwise_aligned_coarse \\ # or obsm/spatial_pairwise_aligned_fine\n",
    "      --spatial-key-out obsm/spatial_manual_fine \\\n",
    "      --per-tile\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the ST and imaging modalities have been aligned, you can segment the images into single cells/nuclei, and then aggregate the spot locations into individual cells for subsequent analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "```bash\n",
    "for sample in mLN_S{2..4}; do\n",
    "     openst from_spacemake \\\n",
    "          --project-id mLN \\\n",
    "          --sample-id \"$sample\" \\\n",
    "          segment \\\n",
    "          --model HE_cellpose_rajewsky \\\n",
    "          --device cuda # ignore if no CUDA-compatible GPU is available \n",
    "done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can assess the segmentation masks with the `openst preview` tool, based on the `napari` image viewer. You can do this section by section, e.g., for section `mLN_S2`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "```bash\n",
    "openst from_spacemake \\\n",
    "     --project-id mLN \\\n",
    "     --sample-id mLN_S2 \\\n",
    "     preview \\\n",
    "     --image-keys uns/spatial/staining_image uns/spatial/staining_image_mask\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-cell quantification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, you can create a single file containing the transcriptomic information aggregated into (segmented) single-cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "```bash\n",
    "for sample in mLN_S{2..4}; do\n",
    "     openst from_spacemake \\\n",
    "          --project-id mLN \\\n",
    "          --sample-id \"$sample\" \\\n",
    "          transcript_assign \\\n",
    "          --spatial-key obsm/spatial_manual_fine \\ # or obsm/spatial_pairwise_fine, if the automated results are satisfying\n",
    "          --mask-in uns/spatial/staining_image_mask\n",
    "done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running all steps above, you will have a single `h5ad` file that contains the cell-by-gene matrix, using the segmented cells and not the pseudocells that were generated by `spacemake` (by default, a regular grid of 7-micron side hexagons).\n",
    "\n",
    "This file can be found at (for `mLN_S2`):\n",
    "\n",
    "`$WORKDIR/spacemake/projects/mLN/processed_data/mLN_S2/multimodal/stitched_segmented.h5ad`\n",
    "\n",
    "This single object contains transcriptomic data per segmented cell, the imaging and segmentation information, and can be used for downstream analysis."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
